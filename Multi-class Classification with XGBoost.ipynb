{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2323\n",
      "Dates         0\n",
      "Category      0\n",
      "Descript      0\n",
      "DayOfWeek     0\n",
      "PdDistrict    0\n",
      "Resolution    0\n",
      "Address       0\n",
      "X             0\n",
      "Y             0\n",
      "dtype: int64\n",
      "Dates         0\n",
      "DayOfWeek     0\n",
      "PdDistrict    0\n",
      "Address       0\n",
      "X             0\n",
      "Y             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Load datasets\n",
    "data_train = pd.read_csv('train2.csv')\n",
    "data_test = pd.read_csv('test2.csv', index_col=0)\n",
    "\n",
    "# Check and drop duplicated values in training data\n",
    "print(data_train.duplicated().sum())\n",
    "data_train.drop_duplicates(keep='first', inplace=True)\n",
    "\n",
    "# Check null values in both datasets\n",
    "print(data_train.isnull().sum())\n",
    "print(data_test.isnull().sum())\n",
    "\n",
    "# Preprocess the 'Dates' column to extract features\n",
    "for data in [data_train, data_test]:\n",
    "    data['Dates'] = pd.to_datetime(data['Dates'])\n",
    "    data['Year'] = data['Dates'].dt.year\n",
    "    data['Month'] = data['Dates'].dt.month\n",
    "    data['Day'] = data['Dates'].dt.day\n",
    "    data['Hour'] = data['Dates'].dt.hour\n",
    "    data.drop('Dates', axis=1, inplace=True)\n",
    "\n",
    "# Data preprocessing\n",
    "# Drop unnecessary columns from training data and split features and labels\n",
    "X_train = data_train.drop(['Category', 'Resolution', 'Descript'], axis=1)\n",
    "y_train = data_train['Category']\n",
    "\n",
    "# Encode categorical features and labels\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "X_train['PdDistrict'] = le.fit_transform(X_train['PdDistrict'])\n",
    "X_train['DayOfWeek'] = le.fit_transform(X_train['DayOfWeek'])\n",
    "X_train['Address'] = le.fit_transform(X_train['Address'])\n",
    "\n",
    "# Feature scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "\n",
    "# Train XGBoost model\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Preprocess test data\n",
    "# Encode categorical features\n",
    "X_test = data_test\n",
    "X_test['PdDistrict'] = le.fit_transform(X_test['PdDistrict'])\n",
    "X_test['DayOfWeek'] = le.fit_transform(X_test['DayOfWeek'])\n",
    "X_test['Address'] = le.fit_transform(X_test['Address'])\n",
    "\n",
    "# Scale test data\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Make predictions\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "# Create and save output DataFrame\n",
    "output = pd.DataFrame({\"Id\": data_test.index, \"Predictions\": preds})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
